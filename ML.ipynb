{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MACHINE LEARNING CLASS DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML:\n",
    "    \n",
    "    def __init__(self,directory1,directory2,rank,group,group_name):\n",
    "        import pandas as pd \n",
    "        import numpy as np\n",
    "        self.directory1 = directory1\n",
    "        self.directory2 = directory2\n",
    "        self.rank = rank\n",
    "        self.group = group\n",
    "        self.group_name = group_name\n",
    "        # Importing the train dataset \n",
    "        dataset1 = pd.read_csv(self.directory1)\n",
    "        size = len(group)\n",
    "        \n",
    "        dataset1.insert(rank,'y',1)\n",
    "        #for i in range(0,size):\n",
    "         #   dataset1.insert(rank+i,i,0)\n",
    "        \n",
    "        X = dataset1.iloc[:, 1:3].values\n",
    "        y = dataset1.iloc[:, rank].values\n",
    "        #y = [0]*size\n",
    "        #for i in range(0,size):\n",
    "          #  y[i] = dataset1.iloc[:, rank+i].values\n",
    "        \n",
    "        k = 0\n",
    "        for i in range(0,size):\n",
    "            y[k:sum(group[0:i+1])] = (dataset1[k:sum(group[0:i+1])].iloc[:, rank].values)*i\n",
    "            k = sum(group[0:i+1])\n",
    "        \n",
    "        #k = 0\n",
    "        #for i in range(0,size):\n",
    "         #   y[i][k:sum(group[0:i+1])] = (dataset1[k:sum(group[0:i+1])].iloc[:, rank+i].values+1)\n",
    "          #  k = sum(group[0:i+1])\n",
    "        \n",
    "       # y = np.asarray(y).T\n",
    "        # importing the test set \n",
    "        dataset2 = pd.read_csv(self.directory2)\n",
    "        X_test = dataset2.iloc[:, 1:3].values\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_test = X_test\n",
    "        \n",
    "    def SVM(self):\n",
    "        \n",
    "        import numpy as np\n",
    "        # Splitting the dataset into the Training set and Test set\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size = 0.01, random_state = 0)\n",
    "        \n",
    "        # Feature Scaling\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_pred = sc.transform(self.X_test)\n",
    "        \n",
    "        # Fitting Kernel SVM to the Training set\n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        # Predicting the Test set results\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        # Making the Confusion Matrix\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        cm1 = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        accuracy_train = sum(np.diag(cm1))/sum(sum(cm1))\n",
    "        # new data pred \n",
    "        y_pred_test = classifier.predict(X_pred)\n",
    "        \n",
    "        size = len(y_pred_test)\n",
    "        predict = [0]*len(self.group)\n",
    "        for i in range (0,size):\n",
    "            for k in range(0,len(self.group)):\n",
    "                if y_pred_test[i] == k:\n",
    "                    predict[k] = predict[k]+1\n",
    "        index = np.argmax(predict)\n",
    "        string = self.group_name[index]\n",
    "        return y_pred, cm1, accuracy_train, y_pred_test, string, self.group, self.group_name, index, predict, self.y, self.X\n",
    "        #return y_pred, cm1, accuracy_train, y_pred_test, self.group, self.group_name, self.y  \n",
    "    \n",
    "    def RF(self):\n",
    "        import numpy as np\n",
    "        # Splitting the dataset into the Training set and Test set\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size = 0.01, random_state = 0)\n",
    "\n",
    "        # Feature Scaling\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_pred = sc.transform(self.X_test)\n",
    "\n",
    "        # Fitting Random Forest Classification to the Training set\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Predicting the Test set results\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        # Making the Confusion Matrix\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        cm1 = confusion_matrix(y_test, y_pred)\n",
    "        accuracy_train = sum(np.diag(cm1))/sum(sum(cm1))\n",
    "        \n",
    "        # new data pred \n",
    "        y_pred_test = classifier.predict(X_pred)\n",
    "        \n",
    "        # Making the Confusion Matrix\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        cm1 = confusion_matrix(y_test, y_pred)\n",
    "        accuracy_train = sum(np.diag(cm1))/sum(sum(cm1))\n",
    "        \n",
    "        \n",
    "        size = len(y_pred_test)\n",
    "        predict = [0]*len(self.group)\n",
    "        for i in range (0,size):\n",
    "            for k in range(0,len(self.group)):\n",
    "                if y_pred_test[i] == k:\n",
    "                    predict[k] = predict[k]+1\n",
    "        index = np.argmax(predict)\n",
    "        string = self.group_name[index]\n",
    "        return y_pred, cm1, accuracy_train, y_pred_test, string, self.group, self.group_name, index, predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
